{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext watermark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from downstream import dstream\n",
    "from hstrat import hstrat\n",
    "from hstrat import _auxiliary_lib as hstrat_aux\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import typing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%watermark -diwmuv -iv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teeplot_subdir = \"2025-09-07-shortcut-naive-comparison\"\n",
    "teeplot_subdir\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstruction_error_data = pd.read_csv(\"https://osf.io/7j3t4/download\")\n",
    "reconstruction_error_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming the null hypothesis for a given sample size and significance level, finds the lowest number $x$ such that $$P(\\text{positives} \\le x) \\ge 0.95$$ Hypothetically, this means that, given a certain effect size, the effect size is reliably detected if the number of positives is greater than this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_expected_positive_rate(num_trials: int, significance: float) -> int:\n",
    "    for i in range(num_trials + 1):\n",
    "        if scipy.stats.binom.cdf(i, num_trials, significance) >= 1 - significance:\n",
    "            return i \n",
    "compute_expected_positive_rate(40, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining the effect size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_detected_effect_size(significance: float, *, num_tests: int = 10, sample_size: typing.Optional[int] = None) -> float:\n",
    "    for multiplier in np.linspace(0, 1, 51):\n",
    "        positives = 0\n",
    "        for _ in range(num_tests):\n",
    "            groups = reconstruction_error_data.groupby([\"differentia_bitwidth\", \"surface_size\", \"fossil_interval\"])\n",
    "            for _, df in groups:\n",
    "                example_data = df[df[\"reconstruction_algorithm\"] == \"shortcut\"][\"error_dropped_fossils\"].to_numpy()\n",
    "                if sample_size is not None:\n",
    "                    num_repeats = int(np.ceil(sample_size / example_data.size))\n",
    "                    example_data = example_data.repeat(num_repeats)[:sample_size]\n",
    "                _, p = scipy.stats.mannwhitneyu(\n",
    "                    example_data,\n",
    "                    example_data + np.random.uniform(size=example_data.size) * example_data.mean() * multiplier,\n",
    "                    alternative=\"two-sided\",\n",
    "                )\n",
    "\n",
    "                if p < significance:\n",
    "                    positives += 1\n",
    "        if positives / num_tests > compute_expected_positive_rate(len(groups), significance):\n",
    "            return {\n",
    "                \"effect_size\": float(multiplier),\n",
    "                \"sample_size\": example_data.size\n",
    "            }\n",
    "        \n",
    "min_detected_effect_size(0.05, sample_size=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running statistical test\n",
    "\n",
    "From the power analysis, we know that if there are more than 4 positives then we have a significant difference. We also know that this is capable of detecting a difference of around 0.40 (with a sample size of 40)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info, df in reconstruction_error_data.groupby([\"differentia_bitwidth\", \"surface_size\", \"fossil_interval\"]):\n",
    "    stat, p = scipy.stats.mannwhitneyu(\n",
    "        df[df[\"reconstruction_algorithm\"] == \"shortcut\"][\"error_dropped_fossils\"],\n",
    "        df[df[\"reconstruction_algorithm\"] == \"naive\"][\"error_dropped_fossils\"],\n",
    "        alternative=\"two-sided\",\n",
    "    )\n",
    "\n",
    "    if p < 0.05:\n",
    "        print(\n",
    "            f\"Significant difference in reconstruction error between shortcut and naive for differentia_bitwidth={info[0]}, surface_size={info[1]}, fossil_interval={info[2]}\"\n",
    "        )\n",
    "        sns.violinplot(\n",
    "            data=df,\n",
    "            x=\"reconstruction_algorithm\",\n",
    "            y=\"error_dropped_fossils\",\n",
    "            inner=\"point\",\n",
    "            split=False,\n",
    "        ).set_title(\n",
    "            f\"differentia_bitwidth={info[0]}, surface_size={info[1]}, fossil_interval={info[2]}\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".binder-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
