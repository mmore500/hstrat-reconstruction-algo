{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from matplotlib.patches import Patch\n",
    "from IPython.display import display\n",
    "%pip install teeplot\n",
    "from teeplot import teeplot as tp\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# OSF identifiers\n",
    "non_adaptive_id = \"tvsc7\"\n",
    "adaptive_id = \"a9bxj\"\n",
    "\n",
    "# load CSV file into DataFrame directly from OSF URL\n",
    "df_non_adaptive = pd.read_csv(f\"https://osf.io/{non_adaptive_id}/download\")\n",
    "df_adaptive = pd.read_csv(f\"https://osf.io/{adaptive_id}/download\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def strip_slice_notation(step_name):\n",
    "    return re.sub(r'\\(\\s*\\d+\\s*/\\s*\\d+\\s*\\)', '', step_name).strip()\n",
    "\n",
    "def combine_slices(df):\n",
    "    df[\"what_base\"] = df[\"what\"].apply(strip_slice_notation)\n",
    "    group_cols = [\n",
    "        \"what_base\",\n",
    "        \"phylo_source_path\",\n",
    "        \"revision\",\n",
    "        \"dstream_S\",\n",
    "        \"dstream_value_bitwidth\",\n",
    "        \"num_tips\",\n",
    "        \"cpu_count\",\n",
    "        \"date\",\n",
    "        \"hostname\",\n",
    "    ]\n",
    "    summed_df = df.groupby(group_cols, as_index=False).agg({\"duration (s)\": \"sum\"})\n",
    "    summed_df.rename(columns={\"what_base\": \"what\"}, inplace=True)\n",
    "    return summed_df\n",
    "\n",
    "\n",
    "summed_non_adaptive = combine_slices(df_non_adaptive)\n",
    "summed_adaptive = combine_slices(df_adaptive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FILL GRAPH**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_non_adaptive[\"method\"] = \"Purifying\\nRegime\"\n",
    "summed_adaptive[\"method\"] = \"Adaptive\\nRegime\"\n",
    "\n",
    "df_combined = pd.concat([summed_non_adaptive, summed_adaptive], ignore_index=True)\n",
    "df_combined[\"duration (h)\"] = df_combined[\"duration (s)\"] / 3600\n",
    "\n",
    "df_hstrat = df_combined[df_combined[\"what\"] == \"hstrat.dataframe.surface_build_tree\"].copy()\n",
    "total_hstrat = df_hstrat.groupby(\"method\")[\"duration (h)\"].sum().reset_index(name=\"hstrat_total_h\")\n",
    "\n",
    "df_parts = df_combined[df_combined[\"what\"] != \"hstrat.dataframe.surface_build_tree\"].copy()\n",
    "\n",
    "def recategorize(what):\n",
    "    if what in [\n",
    "        \"extend_tree_searchtable_cpp_from_exploded\",\n",
    "        \"collapse_unifurcations(dropped_only=True)\"\n",
    "    ]:\n",
    "        return what\n",
    "    else:\n",
    "        return \"postprocessing\"\n",
    "\n",
    "df_parts[\"category\"] = df_parts[\"what\"].apply(recategorize)\n",
    "\n",
    "grouped_parts = df_parts.groupby([\"method\", \"category\"], as_index=False).agg({\"duration (h)\": \"sum\"})\n",
    "total_parts = df_parts.groupby(\"method\")[\"duration (h)\"].sum().reset_index(name=\"parts_total_h\")\n",
    "\n",
    "total_summary = pd.merge(total_hstrat, total_parts, on=\"method\", how=\"left\")\n",
    "total_summary[\"other\"] = total_summary[\"hstrat_total_h\"] - total_summary[\"parts_total_h\"]\n",
    "\n",
    "df_other = total_summary[[\"method\", \"other\"]].copy()\n",
    "df_other = df_other.rename(columns={\"other\": \"duration (h)\"})\n",
    "df_other[\"category\"] = \"other\"\n",
    "\n",
    "final_df = pd.concat([grouped_parts, df_other], ignore_index=True)\n",
    "\n",
    "def plot_billion_tip_reconstruction_fill(data):\n",
    "\n",
    "  ordered_categories = [\n",
    "      \"extend_tree_searchtable_cpp_from_exploded\",\n",
    "      \"collapse_unifurcations(dropped_only=True)\",\n",
    "      \"postprocessing\",\n",
    "      \"other\"\n",
    "  ]\n",
    "\n",
    "  legend_labels = [\n",
    "      \"Extend Tree\",\n",
    "      \"Collapse Unifs\",\n",
    "      \"Postprocess\",\n",
    "      \"Other\"\n",
    "  ]\n",
    "\n",
    "  plt.figure(figsize=(2, 2))\n",
    "  ax = sns.histplot(\n",
    "      data=final_df,\n",
    "      y=\"method\",\n",
    "      hue=\"category\",\n",
    "      weights=\"duration (h)\",\n",
    "      multiple=\"fill\",\n",
    "      discrete=True,\n",
    "      hue_order=ordered_categories,\n",
    "      palette=\"YlGnBu\"\n",
    "  )\n",
    "\n",
    "  ax.set_xlabel(\"Proportion of total time\")\n",
    "  ax.set_ylabel(\"\")\n",
    "\n",
    "  palette = sns.color_palette(\"YlGnBu\", len(ordered_categories))\n",
    "  custom_handles = [\n",
    "      Patch(facecolor=palette[i], label=legend_labels[i])\n",
    "      for i in range(len(legend_labels))\n",
    "  ]\n",
    "\n",
    "  ax.legend(\n",
    "      handles=custom_handles,\n",
    "      bbox_to_anchor=(1.05, 0.5),\n",
    "      loc='center left',\n",
    "      fontsize=8\n",
    "  )\n",
    "\n",
    "\n",
    "\n",
    "tp.tee(plot_billion_tip_reconstruction_fill, data=final_df)\n",
    "\n",
    "display(final_df[[\"method\", \"category\", \"duration (h)\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**STACKED GRAPH**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_non_adaptive[\"method\"] = \"Purifying\\nRegime\"\n",
    "summed_adaptive[\"method\"] = \"Adaptive\\nRegime\"\n",
    "\n",
    "df_combined = pd.concat([summed_non_adaptive, summed_adaptive], ignore_index=True)\n",
    "df_combined[\"duration (h)\"] = df_combined[\"duration (s)\"] / 3600\n",
    "\n",
    "\n",
    "df_hstrat = df_combined[df_combined[\"what\"] == \"hstrat.dataframe.surface_build_tree\"].copy()\n",
    "total_hstrat = df_hstrat.groupby(\"method\")[\"duration (h)\"].sum().reset_index(name=\"hstrat_total_h\")\n",
    "\n",
    "\n",
    "df_parts = df_combined[df_combined[\"what\"] != \"hstrat.dataframe.surface_build_tree\"].copy()\n",
    "\n",
    "def recategorize(what):\n",
    "    if what in [\n",
    "        \"extend_tree_searchtable_cpp_from_exploded\",\n",
    "        \"collapse_unifurcations(dropped_only=True)\"\n",
    "    ]:\n",
    "        return what\n",
    "    else:\n",
    "        return \"postprocessing\"\n",
    "\n",
    "df_parts[\"category\"] = df_parts[\"what\"].apply(recategorize)\n",
    "\n",
    "grouped_parts = df_parts.groupby([\"method\", \"category\"], as_index=False).agg({\"duration (h)\": \"sum\"})\n",
    "total_parts = df_parts.groupby(\"method\")[\"duration (h)\"].sum().reset_index(name=\"parts_total_h\")\n",
    "\n",
    "total_summary = pd.merge(total_hstrat, total_parts, on=\"method\", how=\"left\")\n",
    "total_summary[\"other\"] = total_summary[\"hstrat_total_h\"] - total_summary[\"parts_total_h\"]\n",
    "\n",
    "df_other = total_summary[[\"method\", \"other\"]].copy()\n",
    "df_other = df_other.rename(columns={\"other\": \"duration (h)\"})\n",
    "df_other[\"category\"] = \"other\"\n",
    "\n",
    "final_df = pd.concat([grouped_parts, df_other], ignore_index=True)\n",
    "\n",
    "def plot_billion_tip_reconstruction_stack(data):\n",
    "\n",
    "  ordered_categories = [\n",
    "      \"extend_tree_searchtable_cpp_from_exploded\",\n",
    "      \"collapse_unifurcations(dropped_only=True)\",\n",
    "      \"postprocessing\",\n",
    "      \"other\"\n",
    "  ]\n",
    "\n",
    "\n",
    "  legend_labels = [\n",
    "      \"Extend Trie\",\n",
    "      \"Collapse Unifs\",\n",
    "      \"Postprocess\",\n",
    "      \"Other\"\n",
    "  ]\n",
    "\n",
    "  plt.figure(figsize=(2, 1.2))\n",
    "  ax = sns.histplot(\n",
    "      data=final_df,\n",
    "      y=\"method\",\n",
    "      hue=\"category\",\n",
    "      weights=\"duration (h)\",\n",
    "      multiple=\"stack\",\n",
    "      discrete=True,\n",
    "      hue_order=ordered_categories,\n",
    "      palette=\"YlGnBu\"\n",
    "  )\n",
    "\n",
    "  ax.set_xlabel(\"Total time (hours)\")\n",
    "  ax.set_ylabel(\"\")\n",
    "\n",
    "\n",
    "  ax.set_xlim(0, 4)\n",
    "  ax.set_xticks([0, 1, 2, 3, 4])\n",
    "\n",
    "\n",
    "  palette = sns.color_palette(\"YlGnBu\", len(ordered_categories))\n",
    "  custom_handles = [\n",
    "      Patch(facecolor=palette[i], label=legend_labels[i])\n",
    "      for i in range(len(legend_labels))\n",
    "  ]\n",
    "\n",
    "  ax.legend(\n",
    "      handles=custom_handles,\n",
    "      bbox_to_anchor=(1.05, 0.5),\n",
    "      loc='center left',\n",
    "      fontsize=8\n",
    "  )\n",
    "\n",
    "  sns.move_legend(\n",
    "    ax, \"lower center\",\n",
    "    bbox_to_anchor=(.5, 1), ncol=2, title=None, frameon=False,\n",
    "    columnspacing=0.5,\n",
    "  )\n",
    "\n",
    "tp.tee(plot_billion_tip_reconstruction_stack, data=final_df)\n",
    "\n",
    "display(final_df[[\"method\", \"category\", \"duration (h)\"]])\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
